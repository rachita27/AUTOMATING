{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> AUTOMATING INGESTION FOR AZURE DATA STUDIO(SQL SERVER) </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H5> Libraries </H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Establish Connection</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "cursor established!\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                          'Server=localhost\\SQLEXPRESS08;'\n",
    "                          'Database=master;'\n",
    "                          'Trusted_Connection=yes;',autocommit=True)\n",
    "print(\"done\")\n",
    "cursor = conn.cursor()\n",
    "print(\"cursor established!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H6> Creating Variable to Store Path & Database Name</H6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getcwd() ##change directory to the directory that contains all excel files\n",
    "os.chdir(dir_path) \n",
    "path = os.getcwd() ##storing the path of current directory as variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_nm = \"testing\" ##used to create new folder \n",
    "new_db_nm = \"new_database\" ##database name\n",
    "os.system('mkdir {}'.format(folder_nm)) #\n",
    "new_path=path+\"\\\\\"+folder_nm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Dictionary used to automate Create table Statement </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "        'timedelta64[ns]': 'nvarchar(255)',\n",
    "        'object': 'nvarchar(255)',\n",
    "        'float64': 'float',\n",
    "        'int64': 'int',\n",
    "        'bool': 'string',\n",
    "        'datetime64': 'timestamp',\n",
    "        'datetime64[ns]':'nvarchar(255)'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> FUNCTIONS </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H6> Function to filter only file names </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csvs_excels(path):\n",
    "    list_fil = os.listdir(path) ##list of files in the current directory\n",
    "    list_csv_xlsx = [i for i in list_fil if i.endswith((\".csv\",\".xlsx\"))] ##filtering names of only excel & csv files \n",
    "    return list_csv_xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H6> Moving List of csvs </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_files(list_csvs,path,folder_nm):\n",
    "    for i in list_csvs:\n",
    "        source_path = path.replace(os.sep, '/')+'/'+ i\n",
    "        destination_path  = path.replace(os.sep, '/')+'/'+ folder_nm+ '/'+i\n",
    "        shutil.copy(source_path,destination_path)\n",
    "    print(\"completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Function to read csv & excel files </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file,newpath):\n",
    "    df = pd.read_csv((newpath+\"\\\\\" +file))\n",
    "    return df\n",
    "\n",
    "def read_ex(file,newpath):\n",
    "    fil = (newpath+\"\\\\\" +file)\n",
    "    df = pd.read_excel(fil) #encoding=\"ISO-8859-1\"\n",
    "    return df\n",
    "\n",
    "##this function will read  file depending on file extension\n",
    "def main_func(file,newpath):\n",
    "    ops = {\"csv\":read_csv,\"xlsx\":read_ex,\"xls\":read_ex}\n",
    "    chose_opern = ops.get(file.split(\".\")[-1])\n",
    "    return chose_opern(file,newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Function to create database conn & create database </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_conn(new_db_nm):\n",
    "    cursor.execute(\"\"\"IF NOT EXISTS \n",
    "           (\n",
    "         SELECT name FROM dbo.sysdatabases \n",
    "         WHERE name = N'%s'\n",
    "            )\n",
    "         CREATE DATABASE [%s]\"\"\"%(new_db_nm,new_db_nm))\n",
    "    \n",
    "    print(\"db if not existed created\")\n",
    "    \n",
    "    cursor.execute(\"\"\"USE %s;\"\"\" % (new_db_nm))\n",
    "    print(\"use db: %s\" %(new_db_nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Creating Table</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tbl(new_db_nm,table_nm,tbl_stat):\n",
    "    cursor.execute(\"Use %s;\" % new_db_nm)\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS %s;\" %table_nm)\n",
    "    cursor.execute(\"create table %s (%s);\" % (table_nm, tbl_stat))\n",
    "    print(\"Table %s created\" %table_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Applying Function to Automate Process </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "db if not existed created\n",
      "use db: new_database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['matches_kkr and rcb.csv',\n",
       " 'matches_SHORT.csv',\n",
       " 'matches_SHORT.xlsx',\n",
       " 'men_t20i_team_batting_stats.csv',\n",
       " 'men_t20i_team_bowling_stats.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conn_established()\n",
    "list_csv_xls = list_csvs_excels(path)[40:45] #fileting list of csvs\n",
    "list_csv_xls\n",
    "moving_files(list_csv_xls,path,folder_nm)\n",
    "db_conn(new_db_nm)\n",
    "list_csv_xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table matches_kkrandrcb created\n",
      "Table matches_kkrandrcb created\n",
      "Table matches_SHORT created\n",
      "Table matches_SHORT created\n",
      "Table matches_SHORT created\n",
      "Table matches_SHORT created\n",
      "Table men_t20i_team_batting_stats created\n",
      "Table men_t20i_team_batting_stats created\n",
      "Table men_t20i_team_bowling_stats created\n",
      "Table men_t20i_team_bowling_stats created\n",
      "completed!\n"
     ]
    }
   ],
   "source": [
    "for i in list_csv_xls: \n",
    "    try:\n",
    "         try :\n",
    "            df = main_func(i,new_path)\n",
    "            df1 = df.fillna(\" \")\n",
    "            del df\n",
    "            tbl_nm = i.split(\".\",1)[0].replace(\".\",\"_\").replace(\"$\",\"_\").replace(\"&\",\"_\").replace(\"&\",\"_\").replace(\"-\",\"_\").replace(\" \",\"\").replace(\"+\",\"_\").replace(\"%\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"#\",\"_\").replace(\";\",\"_\").replace(\":\",\"_\").replace(\",\",\"_\").replace(\"'\",\"_\").replace('\\n',\"_\").replace(\"'\",\"_\")\n",
    "            #tbl_nm = re.sub(r'\\d', '_', tbl_nm) ##any number treatment \n",
    "            columns = [i.replace(\".\",\"_\").replace(\"$\",\"_\").replace(\"-\",\"_\").replace(\" \",\"\").replace(\"&\",\"_\").replace(\"+\",\"_\").replace(\"%\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\").replace(\"#\",\"_\").replace(\";\",\"_\").replace(\":\",\"_\").replace(\",\",\"_\").replace(\"'\",\"_\").replace(\"'\",\"_\").replace('\\n',\"_\") for i in df1.columns]\n",
    "            df1 = df1.rename(columns = {x:y for x, y in zip(df1.columns, columns)})\n",
    "            m = df1.dtypes.reset_index().iloc[:,1].astype('str')\n",
    "            tbl_stat = \"  ,\".join((\" {}  {}\").format(o,p) for o,p in list(zip(df1.columns, [replacements[i] for i in m])))#cls\n",
    "            create_tbl(new_db_nm,tbl_nm,tbl_stat)\n",
    "            insert_Stat1 = \"INSERT INTO {}\".format(tbl_nm)+(\"(\"+\",\".join([\"[\"+i+\"]\"  for i in df1.columns])+\")\")+ \" VALUES \" + (\"(\"+\",\".join([\"?\" for i in range(0,len(df1.columns))])+\")\")\n",
    "            \n",
    "            for ind,row in df1.iterrows():\n",
    "                cursor.execute(insert_Stat1,tuple(row))\n",
    "                conn.commit()\n",
    "        \n",
    "            print(\"Uploaded Table {}\"%(tbl_nm))\n",
    "        \n",
    "         except:\n",
    "            df = main_func(i,new_path)\n",
    "            df1 = df.fillna(\" \")\n",
    "            df1 = df1.astype(\"str\")\n",
    "            del df\n",
    "            tbl_nm = i.split(\".\",1)[0].replace(\".\",\"_\").replace(\"$\",\"_\").replace(\"&\",\"_\").replace(\"-\",\"_\").replace(\" \",\"\").replace(\"+\",\"_\").replace(\"%\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"#\",\"_\").replace(\";\",\"_\").replace(\":\",\"_\").replace(\",\",\"_\").replace(\"'\",\"_\").replace('\\n',\"_\").replace(\"'\",\"_\")\n",
    "            #tbl_nm = re.sub(r'\\d', '_', tbl_nm)\n",
    "            columns = [i.replace(\".\",\"_\").replace(\"$\",\"_\").replace(\"-\",\"_\").replace(\" \",\"\").replace(\"&\",\"_\") .replace(\"+\",\"_\").replace(\"%\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\").replace(\"#\",\"_\").replace(\";\",\"_\").replace(\":\",\"_\").replace(\",\",\"_\").replace(\"'\",\"_\").replace(\"'\",\"_\").replace('\\n',\"_\") for i in df1.columns]\n",
    "            df1 = df1.rename(columns = {x:y for x, y in zip(df1.columns, columns)})\n",
    "            m = df1.dtypes.reset_index().iloc[:,1].astype('str')\n",
    "            tbl_stat = \"  ,\".join((\" {}  {}\").format(o,p) for o,p in list(zip(df1.columns, [replacements[i] for i in m])))#cls\n",
    "            create_tbl(new_db_nm,tbl_nm,tbl_stat)\n",
    "            insert_Stat1 = \"INSERT INTO {}\".format(tbl_nm)+(\"(\"+\",\".join([\"[\"+i+\"]\"  for i in df1.columns])+\")\")+ \" VALUES \" + (\"(\"+\",\".join([\"?\" for i in range(0,len(df1.columns))])+\")\")\n",
    "            \n",
    "            for ind,row in df1.iterrows():\n",
    "                cursor.execute(insert_Stat1,tuple(row))\n",
    "                conn.commit()\n",
    "            \n",
    "            print(\"Uploaded Table {}\"%(tbl_nm))      \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(\"completed!\")      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
